
<p align="center">
  <img src="https://github.com/user-attachments/assets/b1646300-912a-4763-8cb9-0ef8c2c4bedf" width="80%">
</p>

# **Azure Kubernetes Miniâ€‘HomelabÂ (3Â Nodes)**

This document serves as a comprehensive guide for deploying and managing a three-node Kubernetes cluster using Microsoft Azure. The purpose of this lab is to cultivate practical skills in provisioning, container orchestration, networking, and observabilityâ€”essential competencies for contemporary infrastructure roles.

[![AzureÂ AKS](https://img.shields.io/badge/Azure-AKS-blue?logo=azure-kubernetes-service\&logoColor=white)](https://azure.microsoft.com/)Â Â [![Kubernetes](https://img.shields.io/badge/K8s-1.30-blue?logo=kubernetes)](https://kubernetes.io/)Â 

---

<p align="center">
  <img src="https://github.com/user-attachments/assets/1e47cef4-28c7-4aa7-b488-15b21b32d0cc" width="70%">
</p>

## ğŸ“œÂ **Introduction**

This repository outlines the steps required to set up a lightweight three-node Kubernetes environment using Azure Kubernetes Service (AKS). Given that the cluster is entirely hosted in the cloud, individuals can engage in experimental learning safely and cost-effectively, making this resource particularly valuable for learners who have yet to acquire physical hardware. All necessary scripts and manifests are included, enabling either precise replication of the lab or its extension into an on-premises homelab in the future.

**Learning objectives**

1. Deploy an AKS cluster with separate worker nodes
2. Manage workloads with YAML and Helm
3. Configure persistent storage & external load balancing
4. Integrate monitoring and autoscaling

Utilization of Azureâ€™s free tier or student credits further contributes to minimizing costs while individuals refine their Kubernetes expertise.
---

## ğŸ—ï¸Â Azure Architecture Snapshot

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            AzureÂ AKSÂ (managed)            â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  â€¢ nodeâ€‘0   Standard_B2s  (worker)        â”‚
â”‚  â€¢ nodeâ€‘1   Standard_B2s  (worker)        â”‚
â”‚  â€¢ nodeâ€‘2   Standard_B2s  (worker)        â”‚
â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  NGINX Pod   â”‚ â€¦ â”‚  NGINX Pod   â”‚    â”‚  â† replicasÂ =Â 2
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                â–²Â PersistentVolumeClaim    â”‚
â”‚                â”‚Â (AzureÂ ManagedÂ Disk)     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     IngressÂ +Â PublicÂ LoadBalancer    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Layer / Feature  | Implementation                       | Purpose                          |
| ---------------- | ------------------------------------ | -------------------------------- |
| Control Plane    | Managed by Azure                     | APIÂ server, scheduler, etcd      |
| Worker Nodes (3) | Â `Standard_B2s` VMs                  | Run pods and services            |
| Workload Example | NGINX DeploymentÂ (2 replicas)        | Demonstrate HA web service       |
| Storage          | AzureÂ Disk PVC                       | Persist data across pod restarts |
| Networking       | LoadBalancerÂ ServiceÂ +Â Ingress       | Expose application externally    |
| Observability    | AzureÂ MonitorÂ +Â Metricsâ€‘ServerÂ +Â HPA | Logs, metrics, autoâ€‘scaling      |

---

## ğŸ”§Â Prerequisites

> ### Environment
>
> â€¢ Azure subscription (orÂ \$100 student credit)
> â€¢ *(Optional)* Public DNS record for ingress
>
> ### Tooling
>
> â€¢ **AzureÂ CLI**Â â‰¥Â 2.60
> â€¢ **kubectl**Â â‰¥Â 1.30
> â€¢ **HelmÂ 3**
>
> *All steps can be completed in the AzureÂ Portal if you prefer GUI over CLI.*

---

## ğŸ› ï¸Â Skills Demonstrated

| Category                | Topics Covered                                                         |
| ----------------------- | ---------------------------------------------------------------------- |
| Cloud Infrastructure    | AKS provisioning â€¢ Nodeâ€‘pool management â€¢ Disk provisioning            |
| Automation &Â CLIÂ Tools  | AzureÂ CLI scripting â€¢ PowerShell â€¢ `kubectl` administration            |
| Kubernetes &Â Networking | YAML manifests â€¢ LoadBalancer services â€¢ Ingress â€¢ Health probes       |
| Monitoring &Â Scaling    | AzureÂ Monitor integration â€¢ Metricsâ€‘Server â€¢ HorizontalÂ PodÂ Autoscaler |

---

## 1ï¸âƒ£Â Cluster Provisioning

**Rationale**Â â€”Â The implementation of three worker nodes ensures fundamental redundancy while maintaining cost efficiency. Azure manages the control plane, thereby reducing operational overhead.


```powershell
$RG       = "rgâ€‘aksâ€‘homelab"
$LOC      = "EastUS"
$CLUSTER  = "aksâ€‘homelab"
$NODES    = 3
$SIZE     = "Standard_B2s"

az group create --name $RG --location $LOC
az aks create `
  --resource-group $RG `
  --name $CLUSTER `
  --node-count $NODES `
  --node-vm-size $SIZE `
  --enable-addons monitoring `
  --generate-ssh-keys
az aks get-credentials --resource-group $RG --name $CLUSTER
kubectl get nodes -o wide
```

*OutcomeÂ â€”Â Three Linux worker nodes register with the managed control plane, and logs/metrics flow into AzureÂ Monitor.*

---

## 2ï¸âƒ£Â Deploy PersistentÂ NGINX Service

**Rationale**Â â€”Â This section demonstrates the process of executing a stateful, load-balanced workload.

<details><summary>pvc.yaml</summary>

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nginx-disk
spec:
  accessModes: [ReadWriteOnce]
  storageClassName: managed-premium
  resources:
    requests:
      storage: 2Gi
```

</details>

<details><summary>nginx-deployment.yaml</summary>

```yaml
apiVersion: apps/v1
kind: Deployment
metadata: { name: nginx-deployment }
spec:
  replicas: 2
  selector: { matchLabels: { app: nginx } }
  template:
    metadata: { labels: { app: nginx } }
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        volumeMounts:
        - mountPath: /usr/share/nginx/html
          name: content
      volumes:
      - name: content
        persistentVolumeClaim:
          claimName: nginx-disk
```

</details>

<details><summary>nginx-service.yaml</summary>

```yaml
apiVersion: v1
kind: Service
metadata: { name: nginx-service }
spec:
  type: LoadBalancer
  selector: { app: nginx }
  ports:
  - port: 80
```

</details>

```bash
kubectl apply -f pvc.yaml
kubectl apply -f nginx-deployment.yaml -f nginx-service.yaml
kubectl get svc nginx-service -w   # wait for EXTERNAL-IP
```

Navigate to the **EXTERNALâ€‘IP** in a browser to confirm deployment.

---

## 3ï¸âƒ£Â Ingress &Â Health Probes

**Rationale**Â â€”Â The Ingress component facilitates hostname-based routing, while health probes guarantee that pods are automatically restarted in the event of failure.

```bash
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install ingress-nginx ingress-nginx/ingress-nginx
```

Add readiness/liveness probes in `nginx-deployment.yaml`, then create `nginx-ingress.yaml` pointing your hostname to the NGINX service.

---

## 4ï¸âƒ£Â Monitoring &Â Autoscaling

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

Deploy HPA (`hpa.yaml`):

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata: { name: nginx-hpa }
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-deployment
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

Generate load and watch scaling with `kubectl get hpa -w`.

---

## ğŸ¡Â Homelab Transition Plan

This roadmap outlines the steps necessary to migrate this cloud-based lab to on-premises hardware that users may already possess.

| Azure Feature         | Bareâ€‘Metal Replacement                                 |
| --------------------- | ------------------------------------------------------ |
| Managed Control Plane | **ASUSÂ ExpertCenterÂ PN64**Â (i5) running `kubeadm init` |
| Worker Nodes (3)      | **IntelÂ NUC11PAKi5 Ã—Â 2**Â running `kubeadm join`        |
| Azure Disk PVC        | NFS share on PN64 or `local-path-provisioner`          |
| Azure LoadBalancer    | **MetalLB** (Layerâ€‘2 mode)                             |
| Azure Monitor         | **Prometheus + Grafana** via Helm                      |

> **Hypervisors:** ProxmoxÂ VE (preferred) or VMwareÂ ESXiÂ Free

### Bareâ€‘Metal Cluster Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Bareâ€‘Metal K8s Cluster          â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  â€¢ PN64  (master)  â€“ kubeadm controlâ€‘planeâ”‚
â”‚  â€¢ NUCâ€‘1 (worker)  â€“ kubeadm node         â”‚
â”‚  â€¢ NUCâ€‘2 (worker)  â€“ kubeadm node         â”‚
â”‚                                           â”‚
â”‚  NFS / localâ€‘path PVC â€¢ MetalLB â€¢ Ingress â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ…Â **Conclusion**

This mini-homelab exemplifies a comprehensive Kubernetes deployment utilizing cost-effective cloud resources. The lab encompasses provisioning, storage, networking, observability, and autoscaling, thereby establishing a solid foundation for further exploration in both cloud and on-premises environments.

**Next Enhancements**

* Replace the demo NGINX app with a production microservice
* Add GitHub Actions for CI/CD automation
* Implement a full observability stack (Prometheus, Grafana, Loki)
* Simulate node failures and document recovery procedures

> *Feel free to fork this repo, adapt it to your environment, and share improvements via pull requests.*

![6386134ab603091521e212c6_60e452a399f5cfb803e6efbf_deployment_process](https://github.com/user-attachments/assets/772a3640-1cc9-429d-861e-60b74eca9a9e)


---

